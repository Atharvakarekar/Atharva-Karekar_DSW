{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Atharva Karekar"
      ],
      "metadata": {
        "id": "eiXWcHsMRKYb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***Modeling:***"
      ],
      "metadata": {
        "id": "pmc7iGmeGCRv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prepare Training Pipeline:"
      ],
      "metadata": {
        "id": "mdAkg6v1GIiE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "au2K9KIxFasy",
        "outputId": "3ea9c15e-a159-4437-8270-8cb3c4e4abd8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model training completed.\n",
            "Model testing completed.\n",
            "Accuracy: 0.825625\n",
            "Predictions: ['top' 'flop' 'flop' ... 'top' 'flop' 'flop']\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "class DataLoader:\n",
        "    def __init__(self, historic_file_path, prediction_file_path):\n",
        "        self.historic_file_path = historic_file_path\n",
        "        self.prediction_file_path = prediction_file_path\n",
        "\n",
        "    def load_data(self):\n",
        "        try:\n",
        "            historic_data = pd.read_csv(self.historic_file_path)\n",
        "            prediction_data = pd.read_csv(self.prediction_file_path)\n",
        "            return historic_data, prediction_data\n",
        "        except FileNotFoundError as e:\n",
        "            print(\"File not found error:\", e)\n",
        "            return None, None\n",
        "        except Exception as e:\n",
        "            print(\"An error occurred while loading data:\", e)\n",
        "            return None, None\n",
        "\n",
        "class DataPreprocessor:\n",
        "    def __init__(self):\n",
        "        self.scaler = StandardScaler()\n",
        "\n",
        "    def preprocess_data(self, data):\n",
        "        if data is not None:\n",
        "            X = data.drop(columns=['success_indicator'], errors='ignore')  # Drop 'success_indicator' if present\n",
        "            X_encoded = pd.get_dummies(X)  # Perform one-hot encoding for categorical variables\n",
        "            X_scaled = self.scaler.fit_transform(X_encoded)  # Scale numeric features\n",
        "            return X_scaled\n",
        "        else:\n",
        "            return None\n",
        "\n",
        "class ModelTrainer:\n",
        "    def __init__(self, model):\n",
        "        self.model = model\n",
        "\n",
        "    def train_model(self, X_train, y_train):\n",
        "        try:\n",
        "            self.model.fit(X_train, y_train)\n",
        "            print(\"Model training completed.\")\n",
        "        except Exception as e:\n",
        "            print(\"An error occurred during model training:\", e)\n",
        "\n",
        "class ModelTester:\n",
        "    def __init__(self, model):\n",
        "        self.model = model\n",
        "\n",
        "    def test_model(self, X_test, y_test):\n",
        "        try:\n",
        "            y_pred = self.model.predict(X_test)\n",
        "            accuracy = accuracy_score(y_test, y_pred)\n",
        "            print(\"Model testing completed.\")\n",
        "            print(\"Accuracy:\", accuracy)\n",
        "        except Exception as e:\n",
        "            print(\"An error occurred during model testing:\", e)\n",
        "\n",
        "class ModelPredictor:\n",
        "    def __init__(self, model):\n",
        "        self.model = model\n",
        "\n",
        "    def predict(self, X_pred):\n",
        "        try:\n",
        "            predictions = self.model.predict(X_pred)\n",
        "            return predictions\n",
        "        except Exception as e:\n",
        "            print(\"An error occurred during model prediction:\", e)\n",
        "\n",
        "\n",
        "# Example usage:\n",
        "historic_file_path = \"historic.csv\"\n",
        "prediction_file_path = \"prediction_input.csv\"\n",
        "\n",
        "data_loader = DataLoader(historic_file_path, prediction_file_path)\n",
        "historic_data, prediction_data = data_loader.load_data()\n",
        "\n",
        "if historic_data is not None and prediction_data is not None:\n",
        "    preprocessor = DataPreprocessor()\n",
        "    X_historic = preprocessor.preprocess_data(historic_data)\n",
        "    X_prediction = preprocessor.preprocess_data(prediction_data)\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X_historic, historic_data['success_indicator'], test_size=0.2, random_state=42)\n",
        "\n",
        "    model = RandomForestClassifier(random_state=42)\n",
        "    trainer = ModelTrainer(model)\n",
        "    trainer.train_model(X_train, y_train)\n",
        "\n",
        "    tester = ModelTester(model)\n",
        "    tester.test_model(X_test, y_test)\n",
        "\n",
        "    predictor = ModelPredictor(model)\n",
        "    predictions = predictor.predict(X_prediction)\n",
        "    print(\"Predictions:\", predictions)\n",
        "else:\n",
        "    print(\"Data loading failed. Please check file paths.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Implement methods for each class to perform respective tasks.**"
      ],
      "metadata": {
        "id": "AcBxcE5MHS_e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "class DataLoader:\n",
        "    def __init__(self, historic_file_path, prediction_file_path):\n",
        "        self.historic_file_path = historic_file_path\n",
        "        self.prediction_file_path = prediction_file_path\n",
        "\n",
        "    def load_data(self):\n",
        "        try:\n",
        "            historic_data = pd.read_csv(self.historic_file_path)\n",
        "            prediction_data = pd.read_csv(self.prediction_file_path)\n",
        "            return historic_data, prediction_data\n",
        "        except FileNotFoundError as e:\n",
        "            print(\"File not found error:\", e)\n",
        "            return None, None\n",
        "        except Exception as e:\n",
        "            print(\"An error occurred while loading data:\", e)\n",
        "            return None, None\n",
        "\n",
        "class DataPreprocessor:\n",
        "    def __init__(self):\n",
        "        self.scaler = StandardScaler()\n",
        "\n",
        "    def preprocess_data(self, data):\n",
        "        if data is not None:\n",
        "            X = data.drop(columns=['success_indicator'], errors='ignore')  # Drop 'success_indicator' if present\n",
        "            X_encoded = pd.get_dummies(X)  # Perform one-hot encoding for categorical variables\n",
        "            X_scaled = self.scaler.fit_transform(X_encoded)  # Scale numeric features\n",
        "            return X_scaled\n",
        "        else:\n",
        "            return None\n",
        "\n",
        "class ModelTrainer:\n",
        "    def __init__(self, model):\n",
        "        self.model = model\n",
        "\n",
        "    def train_model(self, X_train, y_train):\n",
        "        try:\n",
        "            self.model.fit(X_train, y_train)\n",
        "            print(\"Model training completed.\")\n",
        "        except Exception as e:\n",
        "            print(\"An error occurred during model training:\", e)\n",
        "\n",
        "class ModelTester:\n",
        "    def __init__(self, model):\n",
        "        self.model = model\n",
        "\n",
        "    def test_model(self, X_test, y_test):\n",
        "        try:\n",
        "            y_pred = self.model.predict(X_test)\n",
        "            accuracy = accuracy_score(y_test, y_pred)\n",
        "            print(\"Model testing completed.\")\n",
        "            print(\"Accuracy:\", accuracy)\n",
        "        except Exception as e:\n",
        "            print(\"An error occurred during model testing:\", e)\n",
        "\n",
        "class ModelPredictor:\n",
        "    def __init__(self, model):\n",
        "        self.model = model\n",
        "\n",
        "    def predict(self, X_pred):\n",
        "        try:\n",
        "            predictions = self.model.predict(X_pred)\n",
        "            return predictions\n",
        "        except Exception as e:\n",
        "            print(\"An error occurred during model prediction:\", e)\n",
        "\n",
        "\n",
        "# Example usage:\n",
        "historic_file_path = \"historic.csv\"\n",
        "prediction_file_path = \"prediction_input.csv\"\n",
        "\n",
        "# Instantiate DataLoader and load data\n",
        "data_loader = DataLoader(historic_file_path, prediction_file_path)\n",
        "historic_data, prediction_data = data_loader.load_data()\n",
        "\n",
        "# Instantiate DataPreprocessor and preprocess data\n",
        "preprocessor = DataPreprocessor()\n",
        "X_historic = preprocessor.preprocess_data(historic_data)\n",
        "X_prediction = preprocessor.preprocess_data(prediction_data)\n",
        "\n",
        "# Split the historic data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_historic, historic_data['success_indicator'], test_size=0.2, random_state=42)\n",
        "\n",
        "# Instantiate RandomForestClassifier model\n",
        "model = RandomForestClassifier(random_state=42)\n",
        "\n",
        "# Train the model\n",
        "trainer = ModelTrainer(model)\n",
        "trainer.train_model(X_train, y_train)\n",
        "\n",
        "# Test the model\n",
        "tester = ModelTester(model)\n",
        "tester.test_model(X_test, y_test)\n",
        "\n",
        "# Make predictions using the model\n",
        "predictor = ModelPredictor(model)\n",
        "predictions = predictor.predict(X_prediction)\n",
        "print(\"Predictions:\", predictions)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oG5yz3CvHUcO",
        "outputId": "33014297-1a6e-49e2-f97a-9909180ef128"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model training completed.\n",
            "Model testing completed.\n",
            "Accuracy: 0.825625\n",
            "Predictions: ['top' 'flop' 'flop' ... 'top' 'flop' 'flop']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Develop separate scripts for each model type**"
      ],
      "metadata": {
        "id": "geDy0BjjIA-A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Logistic Regression:**"
      ],
      "metadata": {
        "id": "uGEnVxTmICfP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "class LogisticRegressionModel:\n",
        "    def __init__(self):\n",
        "        self.model = LogisticRegression()\n",
        "\n",
        "    def train(self, X_train, y_train):\n",
        "        self.model.fit(X_train, y_train)\n",
        "\n",
        "    def test(self, X_test, y_test):\n",
        "        y_pred = self.model.predict(X_test)\n",
        "        accuracy = accuracy_score(y_test, y_pred)\n",
        "        print(\"Logistic Regression Model Accuracy:\", accuracy)\n",
        "\n",
        "    def predict(self, X_pred):\n",
        "        return self.model.predict(X_pred)\n",
        "\n",
        "# Example usage:\n",
        "# Assuming X_train, y_train, X_test, y_test are available\n",
        "logistic_model = LogisticRegressionModel()\n",
        "logistic_model.train(X_train, y_train)\n",
        "logistic_model.test(X_test, y_test)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pan5mxhUH_94",
        "outputId": "383a7d29-9c17-4dde-cb10-a21b19699a2f"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression Model Accuracy: 0.816875\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Random Forest model:**"
      ],
      "metadata": {
        "id": "1Uhu2oRIIUmR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "class RandomForestModel:\n",
        "    def __init__(self):\n",
        "        self.model = RandomForestClassifier()\n",
        "\n",
        "    def train(self, X_train, y_train):\n",
        "        self.model.fit(X_train, y_train)\n",
        "\n",
        "    def test(self, X_test, y_test):\n",
        "        y_pred = self.model.predict(X_test)\n",
        "        accuracy = accuracy_score(y_test, y_pred)\n",
        "        print(\"Random Forest Model Accuracy:\", accuracy)\n",
        "\n",
        "    def predict(self, X_pred):\n",
        "        return self.model.predict(X_pred)\n",
        "\n",
        "# Example usage:\n",
        "# Assuming X_train, y_train, X_test, y_test are available\n",
        "random_forest_model = RandomForestModel()\n",
        "random_forest_model.train(X_train, y_train)\n",
        "random_forest_model.test(X_test, y_test)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f_43p1QGIZhw",
        "outputId": "a9ecf08a-c630-4496-9ce5-0d7723be4237"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest Model Accuracy: 0.825\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Artificial Neural Network (ANN) model using TensorFlow/Keras:**"
      ],
      "metadata": {
        "id": "QRUfCByGIlxZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "class ANNModel:\n",
        "    def __init__(self, input_shape):\n",
        "        self.model = tf.keras.Sequential([\n",
        "            tf.keras.layers.Dense(64, activation='relu', input_shape=input_shape),\n",
        "            tf.keras.layers.Dense(32, activation='relu'),\n",
        "            tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "        ])\n",
        "        self.model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    def train(self, X_train, y_train, epochs=10, batch_size=32):\n",
        "        self.model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, verbose=0)\n",
        "\n",
        "    def test(self, X_test, y_test):\n",
        "        loss, accuracy = self.model.evaluate(X_test, y_test, verbose=0)\n",
        "        print(\"ANN Model Accuracy:\", accuracy)\n",
        "\n",
        "    def predict(self, X_pred):\n",
        "        return (self.model.predict(X_pred) > 0.5).astype(\"int32\").flatten()\n"
      ],
      "metadata": {
        "id": "vVmug9t_IsWB"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Model Implementation:**"
      ],
      "metadata": {
        "id": "dm-Ph3TTJkuM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Assuming X_train, X_test, y_train, y_test are available\n",
        "\n",
        "# Logistic Regression Model\n",
        "logistic_model = LogisticRegression()\n",
        "logistic_model.fit(X_train, y_train)\n",
        "logistic_predictions = logistic_model.predict(X_test)\n",
        "logistic_accuracy = accuracy_score(y_test, logistic_predictions)\n",
        "print(\"Logistic Regression Model Accuracy:\", logistic_accuracy)\n",
        "\n",
        "# Random Forest Model\n",
        "random_forest_model = RandomForestClassifier()\n",
        "random_forest_model.fit(X_train, y_train)\n",
        "random_forest_predictions = random_forest_model.predict(X_test)\n",
        "random_forest_accuracy = accuracy_score(y_test, random_forest_predictions)\n",
        "print(\"Random Forest Model Accuracy:\", random_forest_accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TWH6QV9SJDIj",
        "outputId": "65f98c80-77db-4fef-e167-651f5690fb4c"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression Model Accuracy: 0.816875\n",
            "Random Forest Model Accuracy: 0.825\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "    We import the necessary classes from scikit-learn, including LogisticRegression, RandomForestClassifier, accuracy_score, and train_test_split.\n",
        "    We instantiate Logistic Regression and Random Forest models.\n",
        "    We train each model using the fit method with the training data.\n",
        "    We make predictions on the test data using the predict method.\n",
        "    We calculate the accuracy of each model using the accuracy_score function.\n",
        "    Finally, we print the accuracy of each model."
      ],
      "metadata": {
        "id": "RhAq8zHiJ1ji"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ANN model, define the architecture including the number of layers, neurons per layer, activation functions, and optimizer.**"
      ],
      "metadata": {
        "id": "yzww2RmNKLOT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# DataLoader class to load data from CSV files\n",
        "class DataLoader:\n",
        "    def __init__(self, historic_file_path, prediction_file_path):\n",
        "        self.historic_file_path = historic_file_path\n",
        "        self.prediction_file_path = prediction_file_path\n",
        "\n",
        "    def load_data(self):\n",
        "        try:\n",
        "            historic_data = pd.read_csv(self.historic_file_path)\n",
        "            prediction_data = pd.read_csv(self.prediction_file_path)\n",
        "            return historic_data, prediction_data\n",
        "        except FileNotFoundError as e:\n",
        "            print(\"File not found error:\", e)\n",
        "            return None, None\n",
        "        except Exception as e:\n",
        "            print(\"An error occurred while loading data:\", e)\n",
        "            return None, None\n",
        "\n",
        "# DataPreprocessor class to preprocess the loaded data\n",
        "class DataPreprocessor:\n",
        "    def __init__(self):\n",
        "        self.scaler = StandardScaler()\n",
        "\n",
        "    def preprocess_data(self, data):\n",
        "        if data is not None:\n",
        "            X = data.drop(columns=['success_indicator'], errors='ignore')  # Drop 'success_indicator' if present\n",
        "            X_encoded = pd.get_dummies(X)  # Perform one-hot encoding for categorical variables\n",
        "            X_scaled = self.scaler.fit_transform(X_encoded)  # Scale numeric features\n",
        "            return X_scaled\n",
        "        else:\n",
        "            return None\n",
        "\n",
        "# ModelTrainer class to train the machine learning model\n",
        "class ModelTrainer:\n",
        "    def __init__(self, model):\n",
        "        self.model = model\n",
        "\n",
        "    def train_model(self, X_train, y_train):\n",
        "        try:\n",
        "            self.model.fit(X_train, y_train)\n",
        "            print(\"Model training completed.\")\n",
        "        except Exception as e:\n",
        "            print(\"An error occurred during model training:\", e)\n",
        "\n",
        "# ModelTester class to evaluate the performance of the trained model\n",
        "class ModelTester:\n",
        "    def __init__(self, model):\n",
        "        self.model = model\n",
        "\n",
        "    def test_model(self, X_test, y_test):\n",
        "        try:\n",
        "            y_pred = self.model.predict(X_test)\n",
        "            accuracy = accuracy_score(y_test, y_pred)\n",
        "            print(\"Model testing completed.\")\n",
        "            print(\"Accuracy:\", accuracy)\n",
        "        except Exception as e:\n",
        "            print(\"An error occurred during model testing:\", e)\n",
        "\n",
        "# ModelPredictor class to make predictions using the trained model\n",
        "class ModelPredictor:\n",
        "    def __init__(self, model):\n",
        "        self.model = model\n",
        "\n",
        "    def predict(self, X_pred):\n",
        "        try:\n",
        "            predictions = self.model.predict(X_pred)\n",
        "            return predictions\n",
        "        except Exception as e:\n",
        "            print(\"An error occurred during model prediction:\", e)\n",
        "\n",
        "# Example usage:\n",
        "historic_file_path = \"historic.csv\"\n",
        "prediction_file_path = \"prediction_input.csv\"\n",
        "\n",
        "# Instantiate DataLoader and load data\n",
        "data_loader = DataLoader(historic_file_path, prediction_file_path)\n",
        "historic_data, prediction_data = data_loader.load_data()\n",
        "\n",
        "# Instantiate DataPreprocessor and preprocess data\n",
        "preprocessor = DataPreprocessor()\n",
        "X_historic = preprocessor.preprocess_data(historic_data)\n",
        "X_prediction = preprocessor.preprocess_data(prediction_data)\n",
        "\n",
        "# Split the historic data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_historic, historic_data['success_indicator'], test_size=0.2, random_state=42)\n",
        "\n",
        "# Instantiate RandomForestClassifier model\n",
        "model = RandomForestClassifier(random_state=42)\n",
        "\n",
        "# Train the model\n",
        "trainer = ModelTrainer(model)\n",
        "trainer.train_model(X_train, y_train)\n",
        "\n",
        "# Test the model\n",
        "tester = ModelTester(model)\n",
        "tester.test_model(X_test, y_test)\n",
        "\n",
        "# Make predictions using the model\n",
        "predictor = ModelPredictor(model)\n",
        "predictions = predictor.predict(X_prediction)\n",
        "print(\"Predictions:\", predictions)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jYLFLyJAJ5Xq",
        "outputId": "a4c4bd17-9741-4a3d-e053-a8b113e03706"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model training completed.\n",
            "Model testing completed.\n",
            "Accuracy: 0.825625\n",
            "Predictions: ['top' 'flop' 'flop' ... 'top' 'flop' 'flop']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "class ANNModel:\n",
        "    def __init__(self, input_shape):\n",
        "        self.model = tf.keras.Sequential([\n",
        "            tf.keras.layers.Dense(64, activation='relu', input_shape=input_shape),\n",
        "            tf.keras.layers.Dense(32, activation='relu'),\n",
        "            tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "        ])\n",
        "        self.model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    def get_model_summary(self):\n",
        "        return self.model.summary()\n",
        "\n",
        "# Example usage:\n",
        "# Assuming input_shape is available\n",
        "input_shape = (10,)  # Example input shape, replace with your actual input shape\n",
        "ann_model = ANNModel(input_shape=input_shape)\n",
        "model_summary = ann_model.get_model_summary()\n",
        "print(model_summary)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DrWgM9e6Kn6Y",
        "outputId": "034c45db-6692-48b4-a063-2cc99e1ecd11"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_12 (Dense)            (None, 64)                704       \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, 32)                2080      \n",
            "                                                                 \n",
            " dense_14 (Dense)            (None, 1)                 33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2817 (11.00 KB)\n",
            "Trainable params: 2817 (11.00 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   Evaluate model performance using appropriate metrics (accuracy, precision, recall, F1-score, ROC-AUC, etc.).\n",
        "*   Save the trained models for future use."
      ],
      "metadata": {
        "id": "qi6MUBdoNl-6"
      }
    }
  ]
}